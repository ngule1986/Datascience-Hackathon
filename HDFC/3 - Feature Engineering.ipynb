{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ENVIRONMENT SETUP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `READING FILES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\ML - Datahack\\\\HDFC Bank\\\\Files'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting working dir\n",
    "import os\n",
    "path = 'G:\\\\ML - Datahack\\\\HDFC Bank\\\\Files'\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_d.csv', low_memory=False)\n",
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_d.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('data_type.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16400, 446)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20442, 446)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DATA TYPES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>Col29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>Col30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>Col31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>Col34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>Col36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type feature\n",
       "0  category   Col29\n",
       "1  category   Col30\n",
       "2  category   Col31\n",
       "3  category   Col34\n",
       "4  category   Col36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['category', 'float', 'int'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "cat_cols = dt[dt.type == 'category'].feature.values\n",
    "\n",
    "# Integer features\n",
    "int_cols = dt[dt.type == 'int'].feature.values\n",
    "\n",
    "# Numeric features\n",
    "float_cols = dt[dt.type == 'float'].feature.values\n",
    "\n",
    "# Train features\n",
    "cols = train.drop('Col2', axis=1).columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RISK RATE FOR CATEGORICAL VARIABLES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values same for below featutes in Train & Test: \n",
      "\n",
      "['Col34', 'Col36', 'Col39', 'Col44', 'Col49', 'Col50', 'Col51', 'Col52', 'Col54', 'Col56', 'Col58', 'Col60', 'Col61', 'Col62', 'Col63', 'Col64', 'Col65', 'Col66', 'Col67', 'Col69', 'Col71', 'Col72', 'Col74', 'Col75', 'Col76', 'Col78', 'Col80', 'Col82', 'Col84', 'Col85', 'Col86', 'Col87', 'Col88', 'Col89', 'Col90', 'Col91', 'Col108', 'Col109', 'Col110', 'Col111', 'Col112', 'Col113', 'Col114', 'Col115', 'Col116', 'Col117', 'Col118', 'Col119', 'Col120', 'Col121', 'Col123', 'Col125', 'Col127', 'Col134', 'Col163', 'Col167', 'Col172', 'Col174', 'Col330', 'Col892', 'Col893', 'Col910', 'Col931', 'Col933', 'Col934', 'Col935', 'Col936', 'Col937', 'Col945', 'Col947', 'Col948', 'Col950', 'Col951', 'Col959', 'Col967', 'Col970', 'Col975', 'Col976', 'Col983', 'Col986', 'Col987', 'Col990', 'Col991', 'Col993', 'Col1001', 'Col1002', 'Col1007', 'Col1009', 'Col1010', 'Col1014', 'Col1015', 'Col1025', 'Col1029', 'Col1049', 'Col1050', 'Col1051', 'Col1068', 'Col1069', 'Col1072', 'Col1118', 'Col1121', 'Col1123', 'Col1127', 'Col1136', 'Col1137', 'Col1140', 'Col1143', 'Col1161', 'Col1165', 'Col1167', 'Col1187', 'Col1205', 'Col1211', 'Col1213', 'Col1214', 'Col1215', 'Col1219', 'Col1221', 'Col1223', 'Col1228', 'Col1231', 'Col1233', 'Col1241', 'Col1245', 'Col1253', 'Col1258', 'Col1263', 'Col1265', 'Col1269', 'Col1272', 'Col1273', 'Col1276', 'Col1277', 'Col1283', 'Col1285', 'Col1301', 'Col1305', 'Col1306', 'Col1307', 'Col1308', 'Col1309', 'Col1313', 'Col1317', 'Col1322', 'Col1330', 'Col1331', 'Col1332', 'Col1333', 'Col1340', 'Col1341', 'Col1346', 'Col1383', 'Col1387', 'Col1388', 'Col1389', 'Col1575', 'Col1589', 'Col1617', 'Col1631']\n"
     ]
    }
   ],
   "source": [
    "# Find features where unique() in train and test are same\n",
    "from collections import Counter\n",
    "\n",
    "rate_cat_col = []\n",
    "\n",
    "for x in cols:\n",
    "    if x in cat_cols:\n",
    "        a = list(np.sort(train[x].unique()))\n",
    "        b = list(np.sort(test[x].unique()))\n",
    "\n",
    "        if Counter(a) == Counter(b):\n",
    "            rate_cat_col.append(x)\n",
    "\n",
    "print(f'Unique values same for below featutes in Train & Test: \\n\\n{rate_cat_col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating risk rate for each category and replace in feature\n",
    "for r_col in rate_cat_col:\n",
    "    # Calculate risk rate \n",
    "    df_rate = train.groupby([r_col, 'Col2']).size()\n",
    "\n",
    "    x1 = df_rate[:,1]\n",
    "    x2 = df_rate[:,1] + df_rate[:,0]\n",
    "\n",
    "    x3 = round(x1/x2*100, 2)\n",
    "\n",
    "    # Create a df with categories and corr values \n",
    "    rate = pd.DataFrame(data = {'category': x3.index.values , 'value': x3.values})\n",
    "    rate = rate.fillna(0)\n",
    "\n",
    "    # replace is dataset\n",
    "    for x,y in zip(rate.category.values, rate.value.values):\n",
    "        train.loc[train[r_col] == x, r_col] = y\n",
    "        test.loc[test[r_col] == x, r_col] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RISK RATE FOR OTHER FEATURES IF ANY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values same for below featutes in Train & Test: \n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Any other feature in dataset having unique values same in test and train\n",
    "rate_other_col = []\n",
    "\n",
    "for x in cols:\n",
    "    if x not in rate_cat_col:\n",
    "        a = list(np.sort(train[x].unique()))\n",
    "        b = list(np.sort(test[x].unique()))\n",
    "\n",
    "        if Counter(a) == Counter(b):\n",
    "            rate_other_col.append(x)\n",
    "\n",
    "print(f'Unique values same for below featutes in Train & Test: \\n\\n{rate_other_col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `IMPUTING MISSING VALUES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing in int64 features\n",
    "for x in int_cols:\n",
    "    if x in cols:\n",
    "        a = train[x].isnull().sum()\n",
    "        b = test[x].isnull().sum()\n",
    "        \n",
    "        if (a!=0) | (b!=0):\n",
    "            print(f'Feature {x} | NaN in Train: {a} | NaN in Test: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing in categorical features\n",
    "for x in cat_cols:\n",
    "    if x in cols:\n",
    "        a = train[x].isnull().sum()\n",
    "        b = test[x].isnull().sum()\n",
    "        \n",
    "        if (a!=0) | (b!=0):\n",
    "            print(f'Feature {x} | NaN in Train: {a} | NaN in Test: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing in float features (only features with > 20%)\n",
    "float_miss = []\n",
    "\n",
    "for x in float_cols:\n",
    "    if x in cols:\n",
    "        a = round(train[x].isnull().sum()/len(train)*100,1)\n",
    "        b = round(test[x].isnull().sum()/len(test)*100,1)\n",
    "        \n",
    "        if (a > 20):\n",
    "            float_miss.append(x)\n",
    "            print(f'Feature {x} | NaN in Train: {a}% | NaN in Test: {b}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(float_miss) > 0:\n",
    "    train.drop(columns=float_miss, axis=1, inplace=True)\n",
    "    test.drop(columns=float_miss, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the values using scikit-learn SimpleImpute Class\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = train.drop('Col2', axis=1)\n",
    "cols = df.columns.values\n",
    "\n",
    "imp_mean = SimpleImputer( strategy='median') #for median imputation replace 'mean' with 'median'\n",
    "\n",
    "imp_mean.fit(df)\n",
    "\n",
    "imputed_train_df = imp_mean.transform(df)\n",
    "\n",
    "train[cols] = imputed_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = test.drop('Col1', axis= 1)\n",
    "\n",
    "imp_mean.fit(dft)\n",
    "\n",
    "imputed_test_df = imp_mean.transform(dft)\n",
    "\n",
    "test[cols] = imputed_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OUTLIER DETECTION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# df = train\n",
    "\n",
    "# X = train.drop('Col2', axis=1) \n",
    "# y = train.Col2\n",
    "\n",
    "# model = IsolationForest(random_state=0)\n",
    "\n",
    "# model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['flag'] = model.predict(df.drop('Col2', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df.flag==1]\n",
    "# train = df.drop('flag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SAVING FILE TO DISK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\ML - Datahack\\\\HDFC Bank\\\\Files'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = 'G:\\\\ML - Datahack\\\\HDFC Bank\\\\Files'\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('done_train.csv', index=False)\n",
    "test.to_csv('done_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
